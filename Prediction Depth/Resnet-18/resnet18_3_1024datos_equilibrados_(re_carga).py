# -*- coding: utf-8 -*-
"""RESNET18-3-1024DATOS-equilibrados (re-carga).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WNXCs4OgckP0EgwGmhhNSDUmE_45L3q4
"""

!pip install faiss-gpu

# imports
import torch
import numpy
import matplotlib.pyplot as plt
from torchvision import models, datasets, transforms
from sklearn.neighbors import KNeighborsClassifier
import faiss
import tqdm
import numpy as np

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.cuda.get_device_name()

def imshow(inp, title=None, mean=numpy.array([0.485, 0.456, 0.406]),std=numpy.array([0.229, 0.224, 0.225])):
    """Show torch tensor"""
    inp = inp.numpy().transpose((1, 2, 0))
    inp = std * inp + mean
    inp = numpy.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)

def imshow_grid(tensors, img_titles=None, title=None,
                mean=numpy.array([0.485, 0.456, 0.406]),
                std=numpy.array([0.229, 0.224, 0.225]),images_per_row = 4):
    """Display a grid of images from tensors"""

    # Ajusta esto según el número de imágenes que deseas por fila
    images_per_row = images_per_row

    if images_per_row == 1:
      num_rows = 1

      # Ajusta el tamaño de la figura según sea necesario
      figsize = (images_per_row * 5, num_rows * 5)

      _, axarr = plt.subplots(num_rows, images_per_row, figsize=figsize)

      inp = tensors[0]

      inp = inp.numpy().transpose((1, 2, 0))
      inp = std * inp + mean
      inp = numpy.clip(inp, 0, 1)

      axarr.imshow(inp)
      if img_titles is not None:
          axarr.set_title(img_titles[0])

      if title is not None:
        plt.suptitle(title, fontsize=15)

      plt.pause(0.001)
      plt.show()

    else:

        # Calcula el número de filas necesario
        num_rows = len(tensors) // images_per_row + int(bool(len(tensors) % images_per_row))

        # Ajusta el tamaño de la figura según sea necesario
        figsize = (images_per_row * 5, num_rows * 5)

        _, axarr = plt.subplots(num_rows, images_per_row, figsize=figsize)

        for i in range(len(axarr.flatten())):
            axarr.flatten()[i].set_yticks([])
            axarr.flatten()[i].set_xticks([])

        for i in range(len(tensors)):
            inp = tensors[i]

            inp = inp.numpy().transpose((1, 2, 0))
            inp = std * inp + mean
            inp = numpy.clip(inp, 0, 1)

            row_index = i // images_per_row
            col_index = i % images_per_row

            if num_rows == 1:
                axarr[col_index].imshow(inp)
                if img_titles is not None:
                    axarr[col_index].set_title(img_titles[i])
            else:
                axarr[row_index, col_index].imshow(inp)
                if img_titles is not None:
                    axarr[row_index, col_index].set_title(img_titles[i])

        if title is not None:
            plt.suptitle(title, fontsize=20)

        plt.pause(0.001)
        plt.show()

# Get dataset
#Si es FALSE y ya esta instalado, no se instala
BATCH_SIZE = 32

train_dataset = datasets.CIFAR10('/data/cifar10/', train=True, download=True,
        transform=transforms.Compose([
            transforms.Resize(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])]))


test_dataset = datasets.CIFAR10('/data/cifar10/', train=False, download=True,
        transform=transforms.Compose([
            transforms.Resize(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])]))

torch.manual_seed(0)

#Separacion de subset con numero de clases represatitivo
train_size = 1500
test_size = 50000 - train_size

pre_subset_train_dataset, resto = torch.utils.data.random_split(train_dataset, [train_size, test_size])

#Si se hace un random split de tamaño 1000 no se mantienen 100 imagenes para cada clase, por ello hacemos
#una busqueda por indices y almacenamos 100 imagenes por clase. Como son 1024 el numero especifico es:
#-clase 0:103
#-clase 1:103
#-clase 2:103
#-clase 3:103
#-resto 102

# Contabilizar numero de imagenes por clase

dict_numero_imagenes = {}
dict_indices = {}

for i in range(0,10):
  clase = "clase_" + str(i)
  dict_indices[clase] = []
  if i in [0, 1, 2, 3]:
    dict_numero_imagenes[clase] = 103
  else:
    dict_numero_imagenes[clase] = 102

#Busqueda de indices por clases
for i in range(0,10):
  key = "clase_" + str(i)
  valor_n_imagenes = dict_numero_imagenes[key]
  for j in range(0,1500):
    if valor_n_imagenes == len(dict_indices[key]):
      break
    if pre_subset_train_dataset[j][1] == i:
      dict_indices[key].append(j)

#Printeamos 3 imagenes por clase y verificamos correcto indexacion.
for i in range(0,10):
  key = "clase_" + str(i)
  imshow_grid([pre_subset_train_dataset[x][0] for x in dict_indices[key][:3]],[f'N imagen: {x}, Clase: {pre_subset_train_dataset[x][1]}'for x in dict_indices[key][:3]],
  title = f'Imagenes para clase {i}',images_per_row = 3)

from torch.utils.data import DataLoader,Subset
#Creamos subsets por temas de memoria

# Número de muestras
num_samples = 1024 #Funciona correctamente con 750

#subset_train_dataset = Subset(train_dataset, range(num_samples))
#subset_trainloader = DataLoader(subset_train_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=False)

subset_train_dataset = []

for i in range(0,10):
  key = "clase_" + str(i)
  valor_n_imagenes = dict_numero_imagenes[key]
  for j in range(0,valor_n_imagenes):
    indice_a_insertar = dict_indices[key][j]
    subset_train_dataset.append(pre_subset_train_dataset[indice_a_insertar])

subset_trainloader = DataLoader(subset_train_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=False)

del train_dataset
del test_dataset
del pre_subset_train_dataset
del dict_numero_imagenes
del dict_indices

len(subset_train_dataset)

imshow(subset_train_dataset[0][0])

class IntermediateReps(torch.nn.Module):

    def __init__(self, model, intermediate_layers):
        super(IntermediateReps, self).__init__()
        self.model = model
        self.intermediate_layers = intermediate_layers
        self._features = {layer: torch.empty(0) for layer in intermediate_layers}
        self.handles = []

        for layer_id in self.intermediate_layers:
            layer = dict([*self.model.named_modules()])[layer_id]
            self.handles.append(
                layer.register_forward_hook(self.save_outputs_hook(layer_id))
            )

    def save_outputs_hook(self, layer_id: str):
        def fn(_, __, output):
            #INPUT KNN
            self._features[layer_id] = output
        return fn

    def forward(self, x):
        _ = self.model(x)
        return self._features

    def remove_handles(self):
        for h in self.handles:
            h.remove()
        self.handles = []

#Revisar el pretrained
model = IntermediateReps(
    models.resnet18(pretrained=True),
    [
        'bn1',
        'layer1.0.bn1',
        'layer1.0.bn2',
        'layer1.1.bn1',
        'layer1.1.bn2',
        'layer2.0.bn1',
        'layer2.0.bn2',
        'layer2.1.bn1',
        'layer2.1.bn2',
        'layer3.0.bn1',
        'layer3.0.bn2',
        'layer3.1.bn1',
        'layer3.1.bn2',
        'fc'
    ]
)

# Get shapes
model = model.eval().to(device)
with torch.no_grad():
    shape_array = model(torch.rand(1,3,224,224).to(device))

import math

K = int(8*math.sqrt(len(subset_train_dataset)))

index_factor_str = f'OPQ128_2048,IVF{K},PQ128'
index_factor_str = f"PCA2048,Flat"
faiss_indices = {
    k :  faiss.IndexIDMap(faiss.IndexFlatL2(int(np.prod(v.shape))))
    for k,v in shape_array.items()}

print("Largo K:",K)
print("Largo faiss indices:",len(faiss_indices))

import os, shutil
base_dir = "Direct"
#Para ejecutar el faiss nuevamente

#Se elimina la carpeta (se garantiza que este vacia)
#shutil.rmtree(base_dir)

#Se crea la carpeta vacia
os.mkdir(base_dir)
print("Directory '% s' created" % base_dir)

# CREATE INDEX

needs_training = False
base_dir = 'Direct/'

with torch.no_grad():
    for i,(data, label) in enumerate(tqdm.tqdm(subset_trainloader)):
        data = data.to(device)
        features = model(data)
        for k,v in features.items():
            if i == 0:
                if not os.path.exists(base_dir + k):
                    os.mkdir(base_dir + k)
                faiss.write_index(faiss_indices[k], base_dir + k + "/trained.index")
            output = torch.flatten(v, start_dim=1).cpu().numpy()
            faiss_indices[k].add_with_ids(output, np.arange(i * BATCH_SIZE, (i + 1) * BATCH_SIZE))
            if i > 0:
                faiss.write_index(faiss_indices[k], base_dir + k + f"/block_{i}.index")
                faiss_indices[k] = faiss.read_index(base_dir + k + "/trained.index")

class ResultHeap:
    """ Combine query results from a sliced dataset (for k-nn search) """

    def __init__(self, nq, k):
        " nq: number of query vectors, k: number of results per query "
        self.I = np.zeros((nq, k), dtype='int64')
        self.D = np.zeros((nq, k), dtype='float32')
        self.nq, self.k = nq, k
        heaps = faiss.float_maxheap_array_t()
        heaps.k = k
        heaps.nh = nq
        heaps.val = faiss.swig_ptr(self.D)
        heaps.ids = faiss.swig_ptr(self.I)
        heaps.heapify()
        self.heaps = heaps

    def add_batch_result(self, D, I, i0):
        assert D.shape == (self.nq, self.k)
        assert I.shape == (self.nq, self.k)
        I += i0
        self.heaps.addn_with_ids(
            self.k, faiss.swig_ptr(D),
            faiss.swig_ptr(I), self.k)

    def finalize(self):
        self.heaps.reorder()

#from faiss import ResultHeap
import glob
idxs = np.random.choice(np.arange(len(subset_train_dataset)),1024, replace = False) #Se sacan 1024 imagenes
subset_data = torch.utils.data.Subset(subset_train_dataset, idxs)
num_to_return = 30

rh = {
    k : ResultHeap(len(idxs), num_to_return)
    for k,v in shape_array.items()
}

with torch.no_grad():
    loader = torch.utils.data.DataLoader(subset_data, batch_size=len(idxs),
            num_workers=8, shuffle = False)
    for i,(data, label) in enumerate(loader):
        data = data.to(device)
        features = model(data)
        for k,v in features.items():
            if k == 'bn1':
                continue
            sub_indexes = glob.glob(base_dir + k + '/block*')
            # knn input (revisar dimension)
            output = torch.flatten(v, start_dim=1).cpu().numpy()
            for s in tqdm.tqdm(sub_indexes):
                index = faiss.read_index(s)
                Di, Ii = index.search(output, num_to_return)
                rh[k].add_batch_result(Di, Ii, 0)

for r in rh.values():
    r.finalize()

y_train = np.array([])
for i,(data, label) in enumerate(tqdm.tqdm(subset_trainloader)):
    y_train = np.append(y_train, label.numpy())

y_actual = np.array([])
for i,(data, label) in enumerate(loader):
    y_actual = np.append(y_actual, label.numpy())

from scipy import stats
predictions = {k:[] for k,v in shape_array.items()}

for i in range(len(idxs)):
    for k in shape_array:
        indices = rh[k].I[i]
        votes = y_train[indices].astype(int)
        predictions[k].append(stats.mode(votes).mode)

# Accuracy of kNN Classifier by Layer
acc = {}
for k in shape_array:
    acc[k] = np.sum(predictions[k] == y_actual) / len(idxs)
    print(f"Accuracy at layer {k}: {acc[k]}")
plt.plot(list(acc.keys()),list(acc.values()))
plt.xticks(rotation = 90)
plt.ylabel('kNN Accuracy')
plt.title('Accuracy of kNN Classifier By Layer')

# Get prediction depth
import pandas as pd

predictions_arr = pd.DataFrame(predictions).values
pds = []
final_preds = []
for i in range(len(idxs)):
    last_val = predictions_arr[i][0]
    depth = 0
    for j in range(1,predictions_arr.shape[1]):
        if predictions_arr[i][j] != last_val:
            last_val = predictions_arr[i][j]
            depth = j
    pds.append(depth)
    final_preds.append(last_val)
print(f'Accuracy of final_preds: {np.sum(final_preds == y_actual) / len(idxs)}')

#Cramos dataframe mas claro
capas = ['bn1','layer1.0.bn1', 'layer1.0.bn2', 'layer1.1.bn1', 'layer1.1.bn2', 'layer2.0.bn1','layer2.0.bn2',
'layer2.1.bn1','layer2.1.bn2', 'layer3.0.bn1', 'layer3.0.bn2', 'layer3.1.bn1', 'layer3.1.bn2','layer fc']

dict = {}

for i in range(len(predictions_arr[0])):
    nombre_col = capas[i]
    dict[nombre_col] = []

df_capas = pd.DataFrame(dict)

for i in range(len(predictions_arr)):
    values = predictions_arr[i].tolist()
    df_capas.loc[len(df_capas.index)] = values

#Agregamos la true label
df_capas['True label'] = y_actual
df_capas['True label'] = df_capas['True label'].astype('int32')

#Agregamos etiqueta de correcto/incorrecto
bool_prediction = []
for i in range(len(predictions_arr)):
    if predictions_arr[i][13] == df_capas['True label'][i]:
        bool_prediction.append('Correcto')
    else:
        bool_prediction.append('Incorrecto')

df_capas['Pred'] = bool_prediction

df_capas.head(10)

#Predicciones KNN por clases

print('Knn Predictions por clases')
print('-'*100)
for i in range(0,10):
    mask = df_capas[df_capas['True label'] == i]
    Count_correctos = mask[mask['Pred'] == 'Correcto'].count()['Pred']
    Count_incorrectos = len(mask) - Count_correctos
    porcentaje_accuracy = round(Count_correctos/len(mask)*100,3)
    print(f'label {i} Correcto: {Count_correctos}, Incorrecto: {Count_incorrectos}, Precision: {porcentaje_accuracy}%')
    print('-'*100)
print(f'Numero de datos total: {len(df_capas)}')

CIFAR10_LABEL_NAMES = ['airplane','automobile',
'bird','cat','deer','dog','frog','horse','ship','truck']

# Get example with low prediction depth
pds = np.array(pds)
sorted_idx = np.argsort(pds) # can use argpartition for
imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],
    [f'Pred: {CIFAR10_LABEL_NAMES[final_preds[x]]}, PD: {pds[x]}, Actual: {CIFAR10_LABEL_NAMES[int(y_actual[x])]}' for x in sorted_idx[:8]],
    title = 'Smallest Prediction Depth')
imshow_grid([subset_data[x][0] for x in sorted_idx[-8:]],
    [f'Pred: {CIFAR10_LABEL_NAMES[final_preds[x]]}, PD: {pds[x]}, Actual: {CIFAR10_LABEL_NAMES[int(y_actual[x])]}' for x in sorted_idx[-8:]],
     title = 'Largest Prediction Depth')

# Accuracy by prediction depth

#Vector de predictions depths unicas
pred_by_pd = {u:[] for u in range(1,len(model.intermediate_layers))}
for i in range(len(pds)):
     pred_by_pd[pds[i]].append(
         final_preds[i] == y_actual[i]
     )
acc_by_pd = {}
for k,v in pred_by_pd.items():
    if len(v) != 0:
        acc_by_pd[k] = np.count_nonzero(v) / len(v)
plt.scatter(list(acc_by_pd.keys()),list(acc_by_pd.values()))
plt.ylabel('kNN Accuracy')
plt.xlabel('Prediction Depth')
plt.title('Accuracy of kNN Classifier By Prediction Depth')

df_capas['Pred_depth'] = pds
PD_unicas = np.sort(df_capas['Pred_depth'].unique())

print('Prediction Depths y acurracy')
print('-'*100)
for i in PD_unicas:
  mask_1 = df_capas[df_capas['Pred_depth'] == i]
  Count_num_correctas = mask_1[mask_1['Pred'] == 'Correcto'].count()[0]
  porcentaje = (Count_num_correctas/len(mask_1))*100
  porcentaje = round(porcentaje,2)

  print(f'Prediction Depth {i}, Cantidad de datos {len(mask_1)}, Predicciones correctas {Count_num_correctas},  Porcentaje correctas {porcentaje}%')
  print('-'*100)

#Vector de traducciones
traduccion = []

for i in range(len(y_actual)):
  value = int(y_actual[i])
  nombre_clase = CIFAR10_LABEL_NAMES[value]
  traduccion.append(nombre_clase)

#Creamos dataframe con la informacon pertenecientes a las clases y a las predictions depth
df_depth_clase = pd.DataFrame({'Clase':y_actual,'Descripcion':traduccion,'Pred_depth':pds,'Prediccion final':df_capas['layer fc']})
df_depth_clase['Clase'] = df_depth_clase['Clase'].astype('int')
df_depth_clase['Pred'] = df_capas['Pred']

df_depth_clase

#Proporcion clases por PD

#Almacenamos este print en un dataframe
dict_proporcion_clases_pd = {}

#Agregamos todas las pd
dict_proporcion_clases_pd['Prediction Depth'] = PD_unicas

#Agregamos resto de las columnas asociadas a las clases
for i in range(0,10):
  key = 'Clase ' + str(i)
  Col_total = 'Total ' + key
  Por_total = 'Prop ' + key
  Acc = 'Acc ' + key
  #Creacion keys
  dict_proporcion_clases_pd[Col_total] = []
  dict_proporcion_clases_pd[Por_total] = []
  dict_proporcion_clases_pd[Acc] = []

dict_proporcion_clases_pd['Total datos'] = []

#Printeos para el colab
print('Proporcion clases por PD')
print('-'*100)
for i in PD_unicas:
    mask = df_depth_clase[df_depth_clase['Pred_depth'] == i]
    total = len(mask)
    print(f'Para la PD: {i}, la proporcion de clases es:')
    for j in range(0,10):
      key = 'Clase ' + str(j)
      Col_total = 'Total ' + key
      Por_total = 'Prop ' + key
      Acc = 'Acc ' + key

      mask_2 = mask[mask['Clase'] == j]
      largo = len(mask_2)
      if largo == 0:
        dict_proporcion_clases_pd[Col_total].append(0)
        dict_proporcion_clases_pd[Por_total].append(0)
        dict_proporcion_clases_pd[Acc].append(0)
        pass
      else:
        value = (largo/total)*100
        porcentaje = round(value,2)
        accuracy = (len(mask_2[mask_2['Pred'] == 'Correcto'])/largo)*100
        porcentaje_acc = round(accuracy,2)

        dict_proporcion_clases_pd[Col_total].append(largo)
        dict_proporcion_clases_pd[Por_total].append(porcentaje)
        dict_proporcion_clases_pd[Acc].append(porcentaje_acc)

        print(f'Clase {j}, total: {len(mask_2)}, porcentaje: {porcentaje}%, accuracy clase: {porcentaje_acc}%')

    dict_proporcion_clases_pd['Total datos'].append(total)
    print(f'Numero de datos del PD: {total}')
    print('-'*100)
print(f'Numero de datos total: {len(df_capas)}')

#Dataframe datos arriba
df_clases_cada_pd = pd.DataFrame(dict_proporcion_clases_pd)
df_clases_cada_pd

valor_moda_depth_por_clase = []
valor_media_depth_por_clase = []

for i in range(len(CIFAR10_LABEL_NAMES)):
  df_hist = df_depth_clase[df_depth_clase['Clase'] == i]
  moda_depth_clase = df_hist['Pred_depth'].mode()[0]
  media_depth_clase = df_hist['Pred_depth'].mean()
  valor_moda_depth_por_clase.append(moda_depth_clase)
  valor_media_depth_por_clase.append(media_depth_clase)

  # Agregar título y etiquetas a los ejes
  plt.title(f'Histograma de la clase {CIFAR10_LABEL_NAMES[i]}')
  plt.xlabel('Prediction depths')
  plt.ylabel('Frecuencia')

  hist = df_hist['Pred_depth'].hist()
  plt.show()

# Mostrar los números específicos en cada barra
for i, valor in enumerate(valor_media_depth_por_clase):
    valor = round(valor,2)
    plt.text(i, valor + 0.1, str(valor), ha='center', va='bottom')

# Girar el eje x en vertical
plt.xticks(rotation='vertical')

# Añadir etiquetas y título
plt.xlabel('Clases')
plt.ylabel('Valor Medio de Prediction Depth')
plt.title('Promedio PD por clase')

plt.bar(CIFAR10_LABEL_NAMES,valor_media_depth_por_clase)

#Vector que se utilizara en todo el siguiente analisis
vector_predicciones = df_depth_clase['Prediccion final'].values

"""### Resultados"""

#Analisis por clase de prediction depth e imagenes
#Clase 0 AVION
df_clase_0 = df_depth_clase[df_depth_clase['Clase'] == 0]
unique_pd_clase_0 = pd.unique(df_clase_0['Pred_depth'])

for i in range(len(unique_pd_clase_0)):
  Prediction_depth = unique_pd_clase_0[i]
  sorted_idx = df_clase_0
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 1 AUTOMOBILE

df_clase_1 = df_depth_clase[df_depth_clase['Clase'] == 1]
unique_pd_clase_1 = pd.unique(df_clase_1['Pred_depth'])

for i in range(len(unique_pd_clase_1)):
  Prediction_depth = unique_pd_clase_1[i]
  sorted_idx = df_clase_1
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 2 BIRD

df_clase_2 = df_depth_clase[df_depth_clase['Clase'] == 2]
unique_pd_clase_2 = pd.unique(df_clase_2['Pred_depth'])

for i in range(len(unique_pd_clase_2)):
  Prediction_depth = unique_pd_clase_2[i]
  sorted_idx = df_clase_2
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 3 CAT

df_clase_3 = df_depth_clase[df_depth_clase['Clase'] == 3]
unique_pd_clase_3 = pd.unique(df_clase_3['Pred_depth'])

for i in range(len(unique_pd_clase_3)):
  Prediction_depth = unique_pd_clase_3[i]
  sorted_idx = df_clase_3
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 4 DEER

df_clase_4 = df_depth_clase[df_depth_clase['Clase'] == 4]
unique_pd_clase_4 = pd.unique(df_clase_4['Pred_depth'])

for i in range(len(unique_pd_clase_4)):
  Prediction_depth = unique_pd_clase_4[i]
  sorted_idx = df_clase_4
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 5 DOG

df_clase_5 = df_depth_clase[df_depth_clase['Clase'] == 5]
unique_pd_clase_5 = pd.unique(df_clase_5['Pred_depth'])

for i in range(len(unique_pd_clase_5)):
  Prediction_depth = unique_pd_clase_5[i]
  sorted_idx = df_clase_5
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 6 DOG

df_clase_6 = df_depth_clase[df_depth_clase['Clase'] == 6]
unique_pd_clase_6 = pd.unique(df_clase_6['Pred_depth'])

for i in range(len(unique_pd_clase_6)):
  Prediction_depth = unique_pd_clase_6[i]
  sorted_idx = df_clase_6
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 7 HORSE

df_clase_7 = df_depth_clase[df_depth_clase['Clase'] == 7]
unique_pd_clase_7 = pd.unique(df_clase_7['Pred_depth'])

for i in range(len(unique_pd_clase_7)):
  Prediction_depth = unique_pd_clase_7[i]
  sorted_idx = df_clase_7
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 8 SHIP

df_clase_8 = df_depth_clase[df_depth_clase['Clase'] == 8]
unique_pd_clase_8 = pd.unique(df_clase_8['Pred_depth'])

for i in range(len(unique_pd_clase_8)):
  Prediction_depth = unique_pd_clase_8[i]
  sorted_idx = df_clase_8
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Analisis por clase de prediction depth e imagenes
#Clase 9 TRUCK

df_clase_9 = df_depth_clase[df_depth_clase['Clase'] == 9]
unique_pd_clase_9 = pd.unique(df_clase_9['Pred_depth'])

for i in range(len(unique_pd_clase_9)):
  Prediction_depth = unique_pd_clase_9[i]
  sorted_idx = df_clase_9
  sorted_idx = sorted_idx[sorted_idx['Pred_depth'] == Prediction_depth].index
  largo = len(sorted_idx)

  if largo == 1:
      value = sorted_idx[0]
      imshow_grid([subset_data[x][0] for x in sorted_idx[:1]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:1]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = 1)

  else:
    if largo >=8:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:8]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:8]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}')

    else:
      imshow_grid([subset_data[x][0] for x in sorted_idx[:largo]],[f'N imagen: {x}, Prediccion KNN: {CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in sorted_idx[:largo]],
      title = f'Imagenes con Prediction Depth = {Prediction_depth}',images_per_row = largo)

#Ahora observamos las imagenes con menos accuracy
#Corresponde al PD = 11

df_low_accuracy = df_depth_clase[df_depth_clase['Pred_depth'] == 11]
descripciones = df_low_accuracy['Descripcion']
Prediction_depth = 11

#Imganes correctamente clasificadas
df_low_accuracy_TRUE =  df_low_accuracy[df_low_accuracy['Pred'] == 'Correcto']
df_low_accuracy_FALSE = df_low_accuracy[df_low_accuracy['Pred'] == 'Incorrecto']
idx_true = df_low_accuracy_TRUE.index
idx_false = df_low_accuracy_FALSE.index

largo_correcto = len(df_low_accuracy_TRUE)
largo_incorrecto = len(df_low_accuracy_FALSE)

if largo_correcto >= 8:
  imshow_grid([subset_data[x][0] for x in idx_true[:8]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_true[:8]],
  title = f'Predicciones correctas con Prediction Depth = {Prediction_depth} ')

if largo_incorrecto >= 8:
  imshow_grid([subset_data[x][0] for x in idx_false[:8]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_false[:8]],
  title = f'Predicciones incorrectas con Prediction Depth = {Prediction_depth}')

else:
  if largo_correcto < 8:
    imshow_grid([subset_data[x][0] for x in idx_true[:largo_correcto]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_true[:largo_correcto]],
    title = f'Predicciones correcta con Prediction Depth = {Prediction_depth}',images_per_row = largo_correcto)

  if largo_incorrecto < 8:
    imshow_grid([subset_data[x][0] for x in idx_false[:largo_incorrecto]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_false[:largo_incorrecto]],
    title = f'Predicciones incorrectas con Prediction Depth = {Prediction_depth}',images_per_row = largo_incorrecto)

#Ahora observamos las imagenes con mas accuracy
#Corresponde al PD = 1

df_high_accuracy_pd1 = df_depth_clase[df_depth_clase['Pred_depth'] == 1]
descripciones = df_high_accuracy_pd1['Descripcion']

#Imganes correctamente clasificadas
idx = df_high_accuracy_pd1.index
largo = len(df_high_accuracy_pd1)

#Ojo que ese images_per_row es solo para este caso
imshow_grid([subset_data[x][0] for x in idx[:largo]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx[:largo]],
title = f'Imagenes con Prediction Depth = {1}', images_per_row = 5)

#Ahora observamos las imagenes con mas accuracy
#Corresponde al PD = 2

df_high_accuracy_pd2 = df_depth_clase[df_depth_clase['Pred_depth'] == 2]
descripciones = df_high_accuracy_pd2['Descripcion']

#Imganes correctamente clasificadas
idx = df_high_accuracy_pd2.index
largo = len(df_high_accuracy_pd2)

#Ojo que ese images_per_row es solo para este caso
imshow_grid([subset_data[x][0] for x in idx[:largo]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx[:largo]],
title = f'Imagenes con Prediction Depth = {2}', images_per_row = largo)

#Ahora observamos las imagenes con mas accuracy
#Corresponde al PD = 3

df_high_accuracy_pd3 = df_depth_clase[df_depth_clase['Pred_depth'] == 3]
descripciones = df_high_accuracy_pd3['Descripcion']

#Imganes correctamente clasificadas
idx = df_high_accuracy_pd3.index
largo = len(df_high_accuracy_pd3)

#Ojo que ese images_per_row es solo para este caso
imshow_grid([subset_data[x][0] for x in idx[:largo]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx[:largo]],
title = f'Imagenes con Prediction Depth = {3}', images_per_row = largo)

#Ahora observamos las imagenes con mas accuracy
#Corresponde al PD = 4

df_high_accuracy_pd4 = df_depth_clase[df_depth_clase['Pred_depth'] == 4]
descripciones = df_high_accuracy_pd4['Descripcion']

#Imganes correctamente clasificadas
idx = df_high_accuracy_pd4.index
largo = len(df_high_accuracy_pd4)

#Ojo que ese images_per_row es solo para este caso
imshow_grid([subset_data[x][0] for x in idx[:largo]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx[:largo]],
title = f'Imagenes con Prediction Depth = {4}', images_per_row = 3)

#Ahora observamos las imagenes con mas accuracy
#Corresponde al PD = 5

df_high_accuracy_pd5 = df_depth_clase[df_depth_clase['Pred_depth'] == 5]
descripciones = df_high_accuracy_pd5['Descripcion']

#Imganes correctamente clasificadas
idx = df_high_accuracy_pd5.index
largo = len(df_high_accuracy_pd5)

#Ojo que ese images_per_row es solo para este caso
imshow_grid([subset_data[x][0] for x in idx[:largo]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx[:largo]],
title = f'Imagenes con Prediction Depth = {5}', images_per_row = 5)

#Ahora observamos las imagenes con mas accuracy, este caso es de las con largest PD
#Corresponde al PD = 10

df_high_accuracy_pd10 = df_depth_clase[df_depth_clase['Pred_depth'] == 10]
descripciones = df_high_accuracy_pd10['Descripcion']

#Imganes correctamente clasificadas
idx = df_high_accuracy_pd10.index
largo = len(df_high_accuracy_pd10)

#Ojo que ese images_per_row es solo para este caso
imshow_grid([subset_data[x][0] for x in idx[:20]],[f'N:{x}, Class:{descripciones[x]} , Prediccion KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx[:20]],
title = f'Imagenes con Prediction Depth = {10}', images_per_row = 5)

#Observamos imagenes de la capa final
#Corresponde al PD = 13

df_high_accuracy_pd13 = df_depth_clase[df_depth_clase['Pred_depth'] == 13]
descripciones = df_high_accuracy_pd13['Descripcion']

Prediction_depth = 13

for i in range(0,10):
  mask = df_high_accuracy_pd13[df_high_accuracy_pd13['Clase'] == i]

  #Imganes correctamente clasificadas
  df_13_TRUE =  mask[mask['Pred'] == 'Correcto']
  df_13_FALSE = mask[mask['Pred'] == 'Incorrecto']
  idx_true = df_13_TRUE.index
  idx_false = df_13_FALSE.index

  largo_correcto = len(df_13_TRUE)
  largo_incorrecto = len(df_13_FALSE)

  if largo_correcto >= 8:
    imshow_grid([subset_data[x][0] for x in idx_true[:8]],[f'N:{x}, Class:{descripciones[x]} , Pred KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_true[:8]],
    title = f'Predicciones correctas clase {i} PD = {Prediction_depth}')

  if largo_incorrecto >= 8:
    imshow_grid([subset_data[x][0] for x in idx_false[:8]],[f'N:{x}, Class:{descripciones[x]} , Pred KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_false[:8]],
    title = f'Predicciones incorrectas clase {i} PD = {Prediction_depth}')

  else:
    if largo_correcto < 8:
      imshow_grid([subset_data[x][0] for x in idx_true[:largo_correcto]],[f'N:{x}, Class:{descripciones[x]} , Pred KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_true[:largo_correcto]],
      title = f'Predicciones correctas clase {i} PD = {Prediction_depth}',images_per_row = largo_correcto)

    if largo_incorrecto < 8:
      imshow_grid([subset_data[x][0] for x in idx_false[:largo_incorrecto]],[f'N:{x}, Class:{descripciones[x]} , Pred KNN:{CIFAR10_LABEL_NAMES[vector_predicciones[x]]}'for x in idx_false[:largo_incorrecto]],
      title = f'Predicciones incorrectas clase {i} PD = {Prediction_depth}',images_per_row = largo_incorrecto)

df_capas

#Guardar los csv asociados a los dataframes
#df_clases_cada_pd

df_clases_cada_pd.to_csv('RESNET18-3-1024DATOS-equilibrados(re-carga).csv', index=False)
df_capas.to_csv('Dataframes_capas_pd_RESNET18-3-1024DATOS-equilibrados(re-carga).csv', index=False)